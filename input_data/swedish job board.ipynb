{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import urllib\n",
    "import urllib.request\n",
    "import re\n",
    "import datetime\n",
    "import logging\n",
    "import time\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "today = str(now.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='SE' + today + '.log', level=logging.DEBUG, format='%(asctime)s:%(name)s:%(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://www.arbetsformedlingen.se/For-arbetssokande/Hitta-jobb/pb-beta/home/search?cyo=3&sort=d&p=1'\n",
    "\n",
    "# create a new Firefox session\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#decleare empty dataframe to store everything related to one role\n",
    "role_dataframe_all = pd.DataFrame()\n",
    "page_number = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#iterate over job type list with dynamic url\n",
    "#for each job iterate through all page to get all positions and store in dataframe, store: position name, company name, location\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "try:\n",
    "\n",
    "    while page_number < 50:\n",
    "        \n",
    "        print('waiting 5 sec')\n",
    "        time.sleep(5)\n",
    "    \n",
    "        print(page_number)\n",
    "        #print('connecting to : {}'.format(str(page_number)), datetime.datetime.now())\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        \n",
    "        job_title_results = soup.find_all('div', attrs={'class':'result-card-list-contianer'}) \n",
    " \n",
    "\n",
    "        #iterate over certain page to store position, company, and location in their own list\n",
    "\n",
    "        pos_all = []\n",
    "        for result in job_title_results:\n",
    "            position = result.find('a').text\n",
    "            job_description_url = result.find('a').get('href')\n",
    "            company = result.find('b').text\n",
    "\n",
    "\n",
    "            pos_all.append([position, job_description_url, company])\n",
    "\n",
    "        #creating merged dataframe\n",
    "        role_dataframe_page = pd.DataFrame(pos_all, columns=['position', 'url', 'company'])\n",
    "\n",
    "        #adding data to role related dataframe\n",
    "        role_dataframe_all = role_dataframe_all.append(role_dataframe_page, ignore_index=True)\n",
    "        #increment page_number\n",
    "        #print(now)\n",
    "        #print(datetime.datetime.now())\n",
    "        page_number += 1\n",
    "        print('waiting 5 seconds')\n",
    "        time.sleep(5)\n",
    "        \n",
    "        python_button = driver.find_element_by_class_name('next-button')\n",
    "        driver.execute_script(\"arguments[0].click();\", python_button)\n",
    "        \n",
    "        \n",
    "except Exception as e:\n",
    "    logging.exception(\"message\")\n",
    "    print(\"Error detected and logged\")\n",
    "    \n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "role_dataframe_all.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "role_dataframe_all.to_excel('SE_IT_' + today+ '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_url = role_dataframe_all['url'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://www.arbetsformedlingen.se' + start_url\n",
    "\n",
    "# create a new Firefox session\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def description_extractor(url):\n",
    "    try:\n",
    "        print(url)\n",
    "        driver.get('https://www.arbetsformedlingen.se' + url)\n",
    "        \n",
    "        print('wait 5 seconds')\n",
    "        time.sleep(5)\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        \n",
    "        try:\n",
    "            job_desc_results = soup.find('p', attrs={'class':'rekryteringsbehov-text break-pre-wrap ng-binding'}).text\n",
    "        except Exception as e:\n",
    "            job_desc_results = soup.find('div', attrs={'class':'annonstext-container'}).text\n",
    "\n",
    "        job_desc_results = re.sub('\\n', '', job_desc_results.strip())\n",
    "        print('wait 5 sec')\n",
    "        time.sleep(5)\n",
    "        return job_desc_results\n",
    "    except Exception as e:\n",
    "        logging.exception(\"message\")\n",
    "        print(\"Error detected and logged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "role_dataframe_all['description'] = role_dataframe_all['url'].apply(description_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "role_dataframe_all.to_excel('SE_FULL' + today+ '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
